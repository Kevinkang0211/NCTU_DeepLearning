{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "#nltk.download()\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "y_train = np.array(pd.get_dummies(x_train.Category))\n",
    "#labels = pd.factorize(x_train.Category)\n",
    "x_train = x_train.drop(['Id','Category'],axis=1)\n",
    "\n",
    "x_test = pd.read_csv(\"test.csv\")\n",
    "x_test = x_test.drop(['Id'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen_train = x_train['Title'].apply(lambda x : len(x.split()))\n",
    "seqlen_test = x_test['Title'].apply(lambda x : len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Title', ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#看句子大概的長度範圍\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(seqlen_train)\n",
    "sns.histplot(seqlen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text preprocessing 在transformer暫時不要做"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Roddick in talks over new coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prodigy join V Festival line-up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sundance to honour foreign films</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dunne keen to commit to Man City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Row over 'police' power for CSOs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>Lufthansa may sue over Bush visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>Rolling out next generation's net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>Mirza makes Indian tennis history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>GTA sequel is criminally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>Go-ahead for new internet names</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1780 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title\n",
       "0       Roddick in talks over new coach\n",
       "1       Prodigy join V Festival line-up\n",
       "2      Sundance to honour foreign films\n",
       "3      Dunne keen to commit to Man City\n",
       "4      Row over 'police' power for CSOs\n",
       "...                                 ...\n",
       "1775  Lufthansa may sue over Bush visit\n",
       "1776  Rolling out next generation's net\n",
       "1777  Mirza makes Indian tennis history\n",
       "1778      GTA sequel is criminally good\n",
       "1779    Go-ahead for new internet names\n",
       "\n",
       "[1780 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Winemaker rejects Foster's offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boeing unveils new 777 aircraft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brown visits slum on Africa trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US blogger fired by her airline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mansfield 0-1 Leyton Orient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>Queen recruit singer for new tour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Slim PlayStation triples sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Vera Drake's Bafta triumph hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>Tindall wants second opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Text message record smashed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>445 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title\n",
       "0     Winemaker rejects Foster's offer\n",
       "1      Boeing unveils new 777 aircraft\n",
       "2     Brown visits slum on Africa trip\n",
       "3      US blogger fired by her airline\n",
       "4          Mansfield 0-1 Leyton Orient\n",
       "..                                 ...\n",
       "440  Queen recruit singer for new tour\n",
       "441     Slim PlayStation triples sales\n",
       "442    Vera Drake's Bafta triumph hope\n",
       "443       Tindall wants second opinion\n",
       "444        Text message record smashed\n",
       "\n",
       "[445 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "token = Tokenizer(num_words=6000)  \n",
    "\n",
    "#使用Tokenizer模組建立token，建立一個字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.fit_on_texts(x_train['Title'])\n",
    "token.fit_on_texts(x_test['Title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq = token.texts_to_sequences(x_train['Title'])\n",
    "x_test_seq = token.texts_to_sequences(x_test['Title'])\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train_seq,maxlen=15)\n",
    "x_test = sequence.pad_sequences(x_test_seq,maxlen=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "embeddings_index = {}\n",
    "#這邊需要自行下載glove檔案到本機路徑\n",
    "f = open(os.path.join('C:/Users/kevin/glove.6B', 'glove.6B.300d.txt'),encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = token.word_index\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4082, 300)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''embedding_matrix.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.3):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"tanh\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        #self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim,weights=[testembedding],\n",
    "                                                                                    input_length = 15,\n",
    "                                                                                     trainable=True)\n",
    "        \n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        \n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 1.3 Transformer Model Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter of Transformer:\n",
    "\n",
    "-Attention head 設為3\n",
    "\n",
    "-Transformer block裡面的隱藏層的layer size設為16\n",
    "\n",
    "-Transfromer block後面接一個 64nodes 的隱藏層，activation function 經實驗過後設為tanh表現最好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#設定EARLY STOP機制 監控loss變化\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_size,embed_dim = embedding_matrix.shape\n",
    "maxlen = 15  # Only consider the first 200 words of each movie review\n",
    "num_heads = 3  # Number of attention heads\n",
    "ff_dim = 16  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "testembedding = embedding_matrix.copy()\n",
    "\n",
    "inputs = layers.Input(shape=(maxlen,))\n",
    "\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "\n",
    "x = embedding_layer(inputs)\n",
    "\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "\n",
    "x = transformer_block(x)\n",
    "\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "x = layers.Dense(64 ,activation=\"tanh\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "outputs = layers.Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "56/56 - 4s - loss: 0.6489 - accuracy: 0.7736\n",
      "Epoch 2/80\n",
      "56/56 - 3s - loss: 0.2413 - accuracy: 0.9275\n",
      "Epoch 3/80\n",
      "56/56 - 3s - loss: 0.1337 - accuracy: 0.9551\n",
      "Epoch 4/80\n",
      "56/56 - 3s - loss: 0.0822 - accuracy: 0.9742\n",
      "Epoch 5/80\n",
      "56/56 - 3s - loss: 0.0379 - accuracy: 0.9888\n",
      "Epoch 6/80\n",
      "56/56 - 3s - loss: 0.0164 - accuracy: 0.9972\n",
      "Epoch 7/80\n",
      "56/56 - 3s - loss: 0.0086 - accuracy: 0.9983\n",
      "Epoch 8/80\n",
      "56/56 - 3s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "56/56 - 3s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "56/56 - 3s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "56/56 - 3s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "56/56 - 3s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "56/56 - 3s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "56/56 - 3s - loss: 9.4609e-04 - accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "56/56 - 3s - loss: 9.1599e-04 - accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "56/56 - 3s - loss: 7.6867e-04 - accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "56/56 - 3s - loss: 7.3732e-04 - accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "56/56 - 3s - loss: 6.5772e-04 - accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "56/56 - 3s - loss: 6.1300e-04 - accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "56/56 - 3s - loss: 5.6273e-04 - accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "56/56 - 3s - loss: 5.4048e-04 - accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "56/56 - 3s - loss: 5.4081e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()  # categorical = one-hot\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])\n",
    "\n",
    "\n",
    "train_history = model.fit(x_train, y_train, \n",
    "                          batch_size=32, \n",
    "                          epochs=80,\n",
    "                          verbose=2,\n",
    "                          callbacks=[callback],\n",
    "                  #validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_predict = model.predict(x_test, verbose=0)\n",
    "\n",
    "y_predict = np.argmax(y_predict,axis=1)\n",
    "\n",
    "classes = ['business','entertainment','politics','sport','tech']\n",
    "\n",
    "result =[]\n",
    "for i in range(len(y_predict)):\n",
    "    result.append([i,classes[y_predict[i]]])\n",
    "    \n",
    "final_result = pd.DataFrame(data=result, index=None, columns=['Id','Category'], dtype=None, copy=False)\n",
    "\n",
    "final_result.to_csv(r'309706033_submission_transformer.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_6_layer_call_fn, embedding_6_layer_call_and_return_conditional_losses, embedding_7_layer_call_fn, embedding_7_layer_call_and_return_conditional_losses, multi_head_attention_3_layer_call_fn while saving (showing 5 of 65). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as embedding_6_layer_call_fn, embedding_6_layer_call_and_return_conditional_losses, embedding_7_layer_call_fn, embedding_7_layer_call_and_return_conditional_losses, multi_head_attention_3_layer_call_fn while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: transformer_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: transformer_model\\assets\n"
     ]
    }
   ],
   "source": [
    "'''model.save('transformer_model')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstructed_model = keras.models.load_model(\"transformer_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "y_predict = reconstructed_model.predict(x_test, verbose=0)\n",
    "\n",
    "y_predict = np.argmax(y_predict,axis=1)\n",
    "\n",
    "classes = ['business','entertainment','politics','sport','tech']\n",
    "\n",
    "result =[]\n",
    "for i in range(len(y_predict)):\n",
    "    result.append([i,classes[y_predict[i]]])\n",
    "    \n",
    "final_result = pd.DataFrame(data=result, index=None, columns=['Id','Category'], dtype=None, copy=False)\n",
    "\n",
    "final_result.to_csv(r'309706033_submission_transformer.csv', index = False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
